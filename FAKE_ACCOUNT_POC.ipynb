{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Fake Social Media Account Detection \u2013 POC Notebook"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1. Introduction\nThis notebook performs exploration and comparison of ML models for fake account detection."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2. Import Libraries"]}, {"cell_type": "code", "metadata": {}, "source": ["import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nimport xgboost as xgb"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3. Load Dataset"]}, {"cell_type": "code", "metadata": {}, "source": ["df = pd.read_excel('fake_dataset.xlsx')\ndf.head()"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4. Dataset Overview"]}, {"cell_type": "code", "metadata": {}, "source": ["df.info()"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["df.describe()"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["df.isnull().sum()"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## 5. Remove Irrelevant Columns"]}, {"cell_type": "code", "metadata": {}, "source": ["columns_to_drop = ['username','user_id','handle','uuid']\ndf = df.drop(columns=[c for c in columns_to_drop if c in df.columns])\ndf.head()"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## 6. Handle Missing Values"]}, {"cell_type": "code", "metadata": {}, "source": ["numeric_cols = df.select_dtypes(include=['int64','float64']).columns\ndf[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n\ncategorical_cols = df.select_dtypes(include=['object','bool']).columns\nfor col in categorical_cols:\n    df[col] = df[col].fillna(df[col].mode()[0])\n\ndf.isnull().sum()"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## 7. Encode Categorical Features"]}, {"cell_type": "code", "metadata": {}, "source": ["df = pd.get_dummies(df, drop_first=True)\ndf.head()"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## 8. Train\u2013Test Split"]}, {"cell_type": "code", "metadata": {}, "source": ["X = df.drop('is_fake', axis=1)\ny = df['is_fake']\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\nX_train.shape, X_test.shape"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## 9. Scale Numeric Features"]}, {"cell_type": "code", "metadata": {}, "source": ["scaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## 10. Train Models"]}, {"cell_type": "code", "metadata": {}, "source": ["log_model = LogisticRegression(max_iter=500)\nlog_model.fit(X_train_scaled, y_train)\nlog_pred = log_model.predict(X_test_scaled)"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["rf_model = RandomForestClassifier(n_estimators=200)\nrf_model.fit(X_train, y_train)\nrf_pred = rf_model.predict(X_test)"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["xgb_model = xgb.XGBClassifier(eval_metric='logloss')\nxgb_model.fit(X_train, y_train)\nxgb_pred = xgb_model.predict(X_test)"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["gb_model = GradientBoostingClassifier()\ngb_model.fit(X_train, y_train)\ngb_pred = gb_model.predict(X_test)"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## 11. Model Evaluation"]}, {"cell_type": "code", "metadata": {}, "source": ["def evaluate(y_true, y_pred, name):\n    print(f\"\\n=== {name} ===\")\n    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n    print(\"Precision:\", precision_score(y_true, y_pred))\n    print(\"Recall:\", recall_score(y_true, y_pred))\n    print(\"F1 Score:\", f1_score(y_true, y_pred))\n\nevaluate(y_test, log_pred, \"Logistic Regression\")\nevaluate(y_test, rf_pred, \"Random Forest\")\nevaluate(y_test, xgb_pred, \"XGBoost\")\nevaluate(y_test, gb_pred, \"Gradient Boosting\")"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## 12. Confusion Matrices"]}, {"cell_type": "code", "metadata": {}, "source": ["models = {\n    \"Logistic Regression\": log_pred,\n    \"Random Forest\": rf_pred,\n    \"XGBoost\": xgb_pred,\n    \"Gradient Boosting\": gb_pred\n}\n\nfor name, preds in models.items():\n    cm = confusion_matrix(y_test, preds)\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n    plt.title(name)\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.show()"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## 13. Feature Importance"]}, {"cell_type": "code", "metadata": {}, "source": ["importances = gb_model.feature_importances_\nplt.figure(figsize=(10,6))\nplt.barh(X.columns, importances)\nplt.title(\"Feature Importance \u2013 Gradient Boosting\")\nplt.show()"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## 14. Conclusion\nGradient Boosting performed the best. This notebook validates model selection for deployment."]}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3"}, "language_info": {"name": "python", "version": "3.10"}}, "nbformat": 4, "nbformat_minor": 5}